# 面试零散问题

## 1、基础知识

### 1.1 NLP基础

#### 1.1.1 NLP常见下游任务

&emsp;&emsp;四大基本任务：分类任务、序列标注任务、句子对关系判断任务、生成式任务；

&emsp;&emsp;模型输出目标：文本到文本、文本到类别


#### 1.1.2 tf、keras、pytorch的差别与选型

&emsp;&emsp;https://zhuanlan.zhihu.com/p/620919451

#### 1.1.3 双塔模型的训练与部署、离线部署与在线服务方式

&emsp;&emsp;在实际的工业应用场景中，分为离线训练和在线服务两个环节。

- 在离线训练阶段，基于训练数据，训练好模型参数。然后将候选库中所有的item集合离线计算得到对应的embedding，并存储进ANN检索系统，比如faiss检索引擎、Milvus向量数据库。
离线计算item集合，主要是因为item的会相对稳定，不会频繁的变动。而对于用户而言，如果将用户行为作为user侧的输入，那么user的embedding会随着用户行为的发生而不断变化，因此对于user侧的embedding需要实时的计算。

- 在线服务阶段，正是因为用户的行为变化需要被即使的反应在用户的embedding中，以更快的反应用户当前的兴趣，即可以实时地体现用户即时兴趣的变化。
因此在线服务阶段需要实时的通过拼接用户特征，输入到user侧的DNN当中，进而得到user embedding，在通过user embedding去faiss中进行ANN检索，
召回最相似的K个item embedding。

### 1.2、预训练模型    

- （1）transformer的原理，encoder和decoder的设计，对bert系列算法的了解，与GPT的对比；与CNN算法的区别

&emsp;&emsp;Transformer网络是一个Encoder-Decoder（编码，解码）的结构，整体是由输入部分，Encoder部分和Decoder部分组成。Encoder端和Decoder端均有6个Block，Encoder端的Block包括两个模块，多头self-attention模块以及一个前馈神经网络模块；Decoder端的Block包括三个模块，Masked多头self-attention模块，多头Encoder-Decoder attention交互模块，以及一个前馈神经网络模块；需要注意：Encoder端和Decoder端中的每个模块都有残差层和Layer Normalization层

&emsp;&emsp;bert系列、原生bert、albert、roberta、wwmbert、sbert、kbert、gpt类模型天然适配生成式下游任务，bert系列由于设计上引入双向transformer，对上下文结合更优秀、对于语义分析类任务表现更优；

1、Transformer模型的核心是self-attention机制，而CNN模型的核心是卷积和池化；

2、Transformer模型可以学习到数据中每个词之间的相关性，而CNN关注于二维局部数据之间的相互关联，随着层的加深，关注区域会更广。
## 2、问题解决

### 2.1、搜推广

-（1）搜索召回，按相关性召回的集合很大但用户每次只浏览前几个导致曝光集很小，用这个曝光集训练排序模型是否合适？这种样本集合偏差问题怎么解决 

&emsp;&emsp;1、调整召回的方式，从内容层面做召回；2、长尾增加曝光量；3、调整排序方法 4、引入一些正则化方法，高频增加干扰，低频减少干扰/引入对抗训练 5、调整排序结果牺牲部分时间段效果拿数据 6、拉长时间轴获得更多样本来训练

-（2）排序模型正负样本的构造，ctr怎么算的

-（3）推荐用的什么模型、特征有哪些

### 2.2、语义理解

-（1）对于下游任务较为常见、但模型复杂度比较高的业务场景如何进行问题解耦（如单纯一个实体识别任务，但是实体数量超过1000个）

-（2）如何做好短文本的分类以及标签的自动构造

&emsp;&emsp;在新闻的文本分类中，由于短新闻特征较少，如果把不同长度的新闻都放入一个分类器分类会造成文本分类效果不好。
我们的解决办法是使用 Milvus 向量搜索引擎可搜索出多条语义近似、评分可靠的长文本分类信息；利用投票法修正短文本的分类。
由于不同新闻长短差异很大，且短新闻特征较少，用同一个分类器对所有新闻进行分类会导致短文本分类的错误率高于长文本分类。
如何批量快速找到这些错误分类的短文本、纠正这些短文本的类别，并将这批数据作为训练用的语料集，成为了一个问题。
人工标注时间周期较长，且正确率难以保证。为了解决这一问题，我们利用bert-as-service把分类器打分超过0.9的长新闻转为语义向量插入Milvus中。
在插入500万条长文本语义向量之后，先遍历短文本新闻，将短文本新闻转化为语义向量，用每条短新闻的语义向量搜索Milvus库获得余弦相似度最高的top20条长新闻。
我们随后对这些语义最相似的 top 20 条长新闻的类别进行统计。如果其中超过 18 条新闻的类别都一致，且与查询的短新闻类别不一致，
我们则认为短新闻的类别分类错误，需要纠正为与这 18 条长新闻相同的类别。我们迅速找到了全年所有分类错误的短文本，这些短文本的类别经过纠正后，
人工抽查显示文本类别的准确率超过 95%。通过利用高置信度的长文本类别信息来修正短文本的分类，我们很短时间内找到了大批 badcase 及对应的正确标注类别。
这为我们训练出短文本分类器提供了很好的语料，有助于训练出更好的短文本分类器。

## 3、前沿问题了解

## 3、项目难点与解决方式